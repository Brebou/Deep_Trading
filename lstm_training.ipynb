{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80a0664c",
   "metadata": {},
   "source": [
    "# Electricity predicteur\n",
    "LSTM based model for Electricity consommation prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ede653f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr = lr)\n",
    "\n",
    "# Part 1 of training\n",
    "print('-- Training the model --')\n",
    "train_lstm(model,\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    nepochs,\n",
    "    path_logs = path_logs,\n",
    "    path_model = path_model,\n",
    "    batch_size = batch_size,\n",
    "    device = device)\n",
    "\n",
    "torch.save(model.state_dict(), path_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54b2f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# Training a model #\n",
    "####################\n",
    "\n",
    "\n",
    "# Importing a LstmNet\n",
    "model = LSTMNet(input_dim,\n",
    "\thidden_size = hidden_dim,\n",
    "\tnum_layers = num_layers,\n",
    "\tout_size = input_dim)\n",
    "\n",
    "# Load weights if specified\n",
    "if model_path != '':\n",
    "    model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "\n",
    "# Changing to appropriate device\n",
    "model.to(device)\n",
    "\n",
    "print(model)\n",
    "print(\"Number of Parameters :\", sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7c485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataset path :', dataset_path)\n",
    "print('batch_size :', batch_size)\n",
    "\n",
    "# Import the dataset\n",
    "df = pd.read_csv(dataset_path)\n",
    "df = df[[col]]\n",
    "print(df)\n",
    "\n",
    "# Normalizing data\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled_dataset = scaler.fit_transform(df)\n",
    "\n",
    "\n",
    "# Separating the train and test sets\n",
    "train_dataset, test_dataset = train_test_split(\n",
    "    scaled_dataset,\n",
    "    test_size=0.15,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get training and test size\n",
    "train_size, input_dim = train_dataset.shape\n",
    "test_size, _ = test_dataset.shape\n",
    "\n",
    "print('train_size :', train_size)\n",
    "print('test_size :', test_size)\n",
    "print('n_features :', input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4925d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing to mps if available\n",
    "device = torch.device(\"mps\" if torch.mps.is_available() else \"cpu\")\n",
    "print('Device :', device)\n",
    "\n",
    "# Create the directory containing the model, the logs, etc.\n",
    "dir_name = strftime(\"%Y-%m-%d_%H-%M-%S\", gmtime())\n",
    "out_dir = os.path.join(save_dir, dir_name)\n",
    "os.makedirs(out_dir)\n",
    "\n",
    "path_model = os.path.join(out_dir, \"model.pth\")\n",
    "path_model_classif = os.path.join(out_dir, \"model_classif.pth\")\n",
    "path_config = os.path.join(out_dir, \"config.json\")\n",
    "path_logs = os.path.join(out_dir, \"logs.json\")\n",
    "\n",
    "with open(path_config, 'w') as f:\n",
    "    config = {\n",
    "        \"dataset_path\": dataset_path,\n",
    "        \"lr\": lr,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"nepochs\": nepochs,\n",
    "        \"hidden_dim\": hidden_dim\n",
    "    }\n",
    "    json.dump(config, f)\n",
    "    f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5ce1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "dataset_path = \"dataset.csv\"\n",
    "model_path = ''\n",
    "lr = 1e-3\n",
    "batch_size = 8\n",
    "save_dir = \"outputs\"\n",
    "nepochs = 10\n",
    "num_layers = 2\n",
    "hidden_dim = 64\n",
    "label_smoothing = 0.0\n",
    "\n",
    "col = 'AEP_MW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24aa2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time, strftime, gmtime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from LstmNet import *\n",
    "from train_model import *"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
